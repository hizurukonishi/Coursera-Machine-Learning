{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression (重回帰）\n",
    "\n",
    "Week1で行った、単回帰の説明変数が複数になっただけ。\n",
    "\n",
    "Notation\n",
    "\n",
    "n : 被説明変数(feature)の数\n",
    "\n",
    "m : データ数（一般的な統計学の文脈だとNがデータ数なので混乱に注意）\n",
    "\n",
    "y : 被説明変数 [ m, 1 ] vector\n",
    "\n",
    "X : 説明変数 [ m, n ] matrix\n",
    "\n",
    "theta : パラメタ（重み）[ n, 1 ] vector\n",
    "\n",
    "$$ y = X \\theta + \\epsilon$$\n",
    "\n",
    "で誤差（ε）を最小にするパラメタ（θ）を見つける問題。\n",
    "\n",
    "Week2では、この問題を数値的手法、解析的手法の両方で解く。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('C:/Users/a5136731/Desktop/tmpSugi/ex1/ex1data2.txt',delimiter=',',dtype='float')\n",
    "y = data[:,(2)]\n",
    "y = y[:, np.newaxis]\n",
    "X = data[:,(0,1)]\n",
    "m = X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Feature scaling\n",
    "スケーリング前のデータの統計量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Med</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X0</th>\n",
       "      <td>47</td>\n",
       "      <td>2000.680851</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>786.202619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>47</td>\n",
       "      <td>3.170213</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.752843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     N          Avg     Med         Std\n",
       "X0  47  2000.680851  1888.0  786.202619\n",
       "X1  47     3.170213     3.0    0.752843"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def basicStat(X):\n",
    "    N = np.size(X,0)\n",
    "    nameList = np.size(X,1) * ['A']\n",
    "    for i in range(0, np.size(X,1)):\n",
    "        nameList[i] = 'X' + str(i)\n",
    "    Avg = np.mean(X,0)\n",
    "    \n",
    "    df = pd.DataFrame({'N' : np.shape(X)[0],\n",
    "                       'Avg' : np.mean(X,0),\n",
    "                       'Med' : np.median(X,0),\n",
    "                       'Std' : np.std(X,0),\n",
    "                      },\n",
    "                     columns = ['N', 'Avg','Med','Std'],\n",
    "                     index = nameList)\n",
    "    return df\n",
    "\n",
    "df = basicStat(X)\n",
    "df      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "スケーリング後のデータの統計量\n",
    "\n",
    "### Feature scaling\n",
    "Scalingとは、データの範囲をそろえることを指す。\n",
    "スケールがそろっていない場合、Gradient decentの様な繰り返し計算を行う場合に、\n",
    "変数の大きさが収束に影響を与えてしまうのを防ぐ目的がある。\n",
    "\n",
    "\\begin{align*}& \\; & \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} \\; & \\text{for j := 0...n}\\end{align*}\n",
    "\n",
    "\n",
    "Scalingには複数の方法があるが、よく使われるのは2つ\n",
    "\n",
    "Standardization(標準化)\n",
    "\n",
    "$${x^{(i)}_{\\mathrm{std}} = \\frac{x^{(i)} - \\mu}{\\sigma}}$$\n",
    "\n",
    "データを、標準正規分布に従うように変更する。\n",
    "正規分布なので統計的に扱いやすくなるが、外れ値が大きい場合、分散が過大推定されるので注意\n",
    "\n",
    "Normalization（正規化）\n",
    "$${x^{(i)}_{\\mathrm{norm}} = \\frac{x^{(i)} - x_{\\mathrm{min}}}{x_{\\mathrm{max}} - x_\\mathrm{min}}\n",
    "}$$\n",
    "\n",
    "データを無次元化して、一定のレンジに収まるようにする。\n",
    "（外れ値の外れ方も保存される）\n",
    "\n",
    "参考\n",
    "http://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Med</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X0</th>\n",
       "      <td>47</td>\n",
       "      <td>9.448707e-18</td>\n",
       "      <td>-0.143323</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>47</td>\n",
       "      <td>2.710598e-16</td>\n",
       "      <td>-0.226093</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     N           Avg       Med  Std\n",
       "X0  47  9.448707e-18 -0.143323  1.0\n",
       "X1  47  2.710598e-16 -0.226093  1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def featureNormalize(X):\n",
    "    X_norm = X\n",
    "    mu = np.zeros((1,X.shape[1]))\n",
    "    sigma = np.zeros((1,X.shape[1]))\n",
    "    mu = np.average(X_norm, axis = 0)\n",
    "    sigma = np.std(X_norm, axis = 0)\n",
    "    X_norm = ( X_norm - mu )/sigma\n",
    "    return [X_norm, mu, sigma]\n",
    "\n",
    "X, mu, sigma = featureNormalize(X)\n",
    "df = basicStat(X)\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent (最急降下法)\n",
    "\n",
    "最小（最大）値問題を数値的（⇔解析的）に解く手法の一つ。\n",
    "\n",
    "一般的にベクトルθを引数とする関数fに対して、以下の更新ルールでθを求める。\n",
    "\n",
    "$$\\theta := \\theta - \\alpha*\\frac{\\partial f}{\\partial \\theta}  $$\n",
    "\n",
    "重回帰モデルにおいては、コスト関数は二乗誤差、すなわち↓を最小にするパラメタを求める。\n",
    "\n",
    "$$J(\\theta) = \\dfrac {1}{2m} \\displaystyle \\sum_{i=1}^m \\left (h_\\theta (x^{(i)}) - y^{(i)} \\right)^2$$\n",
    "\n",
    "ここで\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_k} =　\\dfrac {1}{m} * \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_k^{(i)} $$\n",
    "\n",
    "なので、それぞれのθに対して、以下のルールで収束するまでθを更新する。\n",
    "\n",
    "\\begin{align*}& \\; & \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} \\; & \\text{for j := 0...n}\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "和記号を使わずに、すべて行列で表現しようとすると、\n",
    "\n",
    "$$J(\\theta) = \\dfrac {1}{2m} (\\theta X - y)^{T} (\\theta X - y)$$\n",
    "\n",
    "\n",
    "\\begin{align*}\\nabla J(\\theta)= \\frac 1m X^{T} (\\theta X - y) \\newline\\end{align*}\n",
    "\n",
    "ここで\n",
    "\n",
    "$$\\nabla J(\\theta)  = \\begin{bmatrix}\\frac{\\partial J(\\theta)}{\\partial \\theta_0}   \\newline \\frac{\\partial J(\\theta)}{\\partial \\theta_1}   \\newline \\vdots   \\newline \\frac{\\partial J(\\theta)}{\\partial \\theta_n} \\end{bmatrix}$$\n",
    "\n",
    "これにより、\n",
    "\n",
    "$$\\theta := \\theta - \\alpha \\nabla J(\\theta)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x18839dc0e10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxHJEAp8EZEM8f8BSvHQ+xEuuJYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1883c8b1400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gradientDescent(X, y, theta, alpha, num_iters):\n",
    "    m = len(y)\n",
    "    J_history = np.zeros((num_iters,1))\n",
    "    for i in range(0, num_iters):\n",
    "        theta = theta - (alpha/m) * np.transpose(X).dot(X.dot(theta) - y)\n",
    "        J_history[i] = computeCost(X,y,theta)\n",
    "    return [theta, J_history]\n",
    "\n",
    "def computeCost(X, y, theta):\n",
    "    m = len(y)\n",
    "    tmp = ( X.dot(theta) - y )\n",
    "    J = (1/(2*m)) * np.transpose(tmp).dot(tmp)\n",
    "    return J\n",
    "\n",
    "    \n",
    "'load data'\n",
    "data = np.loadtxt('C:/Users\\main/Documents/MATLAB/ex1/ex1data2.txt',delimiter=',',dtype='float')\n",
    "y = (data[:,(2)])\n",
    "' this bit was hard to find the way..'\n",
    "y = y[:, np.newaxis]\n",
    "X = data[:,(0,1)]\n",
    "m = len(X)\n",
    "'normalize data'\n",
    "X, mu, sigma = featureNormalize(X)\n",
    "'add intercept'\n",
    "X = np.c_[np.ones(m),X]\n",
    "\n",
    "'gradient descent'\n",
    "alpha = 0.01\n",
    "num_iters = 400\n",
    "theta = np.zeros((3,1))\n",
    "theta, J_history = gradientDescent(X, y, theta, alpha, num_iters)\n",
    "\n",
    "plt.plot(range(0,num_iters), J_history)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "titleStr = 'Alpha =', str(alpha)\n",
    "plt.title(titleStr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 正規方程式 (Normal Equation)\n",
    "\n",
    "$$ y = X \\theta + \\epsilon$$\n",
    "\n",
    "は解析解をもつ（(X'X)の逆行列が存在する場合）\n",
    "\n",
    "$$\\theta = (X^{\\mathrm{T}}X)^{-1}X^{\\mathrm{T}}y$$\n",
    "\n",
    "逆行列が計算しない場合は、一般化逆行列（pythonではnumpy.linalg.pinv)で計算可能。\n",
    "\n",
    "ただし、逆行列が計算できないのは\n",
    "\n",
    "1. Xの要素が線形関係にある\n",
    "2. データ数に比べて、パラメタの数が大きすぎる\n",
    "\n",
    "場合。なので、計算ができるからと言って、安易に一般化逆行列を使わないほうがいい。\n",
    "2はすぐに気づくはず。1に注意。\n",
    "\n",
    "単純な重回帰であれば、iterationも不要だし、ahlpaも決めなくてもよいので、解析解の方がよい。\n",
    "パラメータ数を超えたら数値解の方が早くなる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def normalEq(X,y):\n",
    "    theta = np.linalg.inv(np.transpose(X).dot(X)) \n",
    "    theta = theta.dot(np.transpose(X).dot(y))\n",
    "    return theta\n",
    "\n",
    "'normal equation'\n",
    "data = np.loadtxt('C:/Users/a5136731/Desktop/tmpSugi/ex1/ex1data2.txt',delimiter=',',dtype='float')\n",
    "y = (data[:,(2)])\n",
    "' this bit was hard..'\n",
    "y = y[:, np.newaxis]\n",
    "X = data[:,(0,1)]\n",
    "X = np.c_[np.ones(m),X]\n",
    "\n",
    "theta = normalEq(X,y);\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
